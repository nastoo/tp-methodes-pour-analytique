{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infos ( à supprimer ensuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables à ajouter issues des recherches biblio ( à supprimer ensuite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable(s): \n",
    "\n",
    "- Population des pays représentés \n",
    "- Variable indiquant si le pays est communiste ou pas \n",
    "- Variable indiquant si le pays est stable ou pas \n",
    "- Variable indiquant si le pays est émergeant ou pas ( otherwise pauvre , riche à peaufiner par la suite) \n",
    "- Variable indiquant si le pays a la culture du sport ou pas. \n",
    "- Variable indiquant le PIB par habitant \n",
    "- Variable indiquant les financements alloués aux sports (olympiques ou pas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut créer le train et le test avec des données 2024 , il faut les construire , il faut aussi savoir traiter le fait que cette fois ci la Russie ne sera pas disponible .\n",
    "Faire indice : pays perturbé 1 avec Russie par exemple ou bien on enlève la Russie  (contexte géopolitique simple, on tah les années où j'ai eu un pb )\n",
    "\n",
    "But c'est de prédire le nombre de médailles pour chaque pays , indicateur simple \n",
    "EXTRA POUR AVOIR 20 : Attribuer un poid aux médailles -> pour potentiellement savoir le nb d'or , argent , bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention au COVID 19 , influence public , web scrapping sur 30 ans de tous les pays qui ont organisé les jeux \n",
    "Attention aux pays pas autorisés à concourir \n",
    "Pays en guerre qui envoient moins d'athlètes \n",
    "Ukraine \n",
    "Palestine \n",
    "Iles caiman -> doivent être rattachées à un pays \n",
    "\n",
    "JO hiver \n",
    "JO été Corrélation \n",
    "Apparition des femmes dans les JO ( échantillonnage ) \n",
    "\n",
    "Culture du sport : Comment la créer ? \n",
    "Budget alloué aux sports (investissement , infrastructures ... ) \n",
    "Nb de professionnels \n",
    "Nb de licencés \n",
    "Nb de sports olympiques disponibles à l'école "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable : Pays Communiste ou pas \n",
    "\n",
    "Croissance pays économique \n",
    "\n",
    "Athlète à partir de 25 ans il n'a plus le niveau : on commence à partir de 2000 , JO Sydney \n",
    "\n",
    "Indice dvp des pays à recevoir \n",
    "\n",
    "Variable pays organisateur \n",
    "\n",
    "Sport qui ont des gens avec un âge bien définie (exemple skate Japonais c'est que des jeunes <= 18 ans)\n",
    "\n",
    "Dataset coupes mondes de discipline  \n",
    "    \n",
    "Variable Note selon l'âge \n",
    "\n",
    "Athlète qui sont comptés comme participant à deux pays \n",
    "\n",
    "Variable : religion majoritaire pays \n",
    "\n",
    "Espérance de vie par pays \n",
    "Variable pays dvp ou pas \n",
    "\n",
    "\n",
    "Recupérer données JO 2018 et 2021\n",
    "\n",
    "Variable Poids par Médailles : échelloner les JO de 1 à 10 pour \n",
    "Variable Poids par année : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction  (Business Understanding) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Détermination objectifs métier , analytique du projet \n",
    "\n",
    "\n",
    "Objectifs métiers du projet :\n",
    "\n",
    "Promotion de la performance sportive : Utiliser les données des Jeux olympiques pour améliorer la performance sportive.\n",
    "\n",
    "Optimisation des ressources : Identifier les sports les plus prometteurs pour optimiser les investissements sportifs.\n",
    "\n",
    "Prédiction des tendances : Prédire les performances futures des pays et des athlètes en se basant sur les données historiques.\n",
    "\n",
    "Analyse de la participation : Analyser la participation mondiale aux Jeux olympiques pour identifier les opportunités de croissance.\n",
    "\n",
    "-------\n",
    "Objectifs analytiques du projet :\n",
    "\n",
    "Analyse des performances : Évaluer les performances des pays, des équipes et des athlètes aux Jeux olympiques.\n",
    "\n",
    "Identification des facteurs de réussite : Identifier les clés du succès dans différents sports et disciplines.\n",
    "\n",
    "Visualisation des données : Créer des visualisations interactives pour présenter les tendances et les comparaisons de manière compréhensible.\n",
    "\n",
    "Modélisation prédictive : Développer des modèles prédictifs pour estimer les performances futures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Identifier les contraintes , limites et risque du projet\n",
    "\n",
    "Qualité des données : Les données historiques peuvent être incomplètes ou imprécises.\n",
    "\n",
    "Variabilité des performances : Les performances sportives sont influencées par de nombreux facteurs difficiles à quantifier.\n",
    "\n",
    "Interprétation des résultats : Les résultats doivent être interprétés avec prudence en raison de la subjectivité des performances sportives.\n",
    "\n",
    "Protection des données : Respecter les règles de confidentialité et de protection des données lors de l'analyse des données.\n",
    "\n",
    "Dépendance aux technologies : Le projet dépend de technologies telles que l'analyse de données, la modélisation statistique, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Chargement des packages si besoin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext ipython_memory_usage \n",
    "!pip install ydata_profiling\n",
    "!pip install wbgapi\n",
    "!pip install unidecode\n",
    "!pip install nltk\n",
    "\n",
    "import ipython_memory_usage.ipython_memory_usage as imu\n",
    "from describe_csv import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import wbgapi as wb\n",
    "import requests\n",
    "import re\n",
    "import datetime\n",
    "import nltk\n",
    "import bs4\n",
    "import unidecode\n",
    "\n",
    "from ydata_profiling import ProfileReport\n",
    "from pandas.api.types import is_numeric_dtype, is_object_dtype\n",
    "from scipy.stats import chi2_contingency\n",
    "from pivottablejs import pivot_ui\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline, make_union\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, RobustScaler, FunctionTransformer\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "imu.start_watching_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CODE \n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Année de début d'analyse\n",
    "START_YEAR = 1984"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bases de données disponibles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_athlete=pd.read_csv('data/athlete_events.csv')\n",
    "df_region=pd.read_csv('data/noc_regions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## EDA sur la base de ces données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_athlete.merge(df_region,on='NOC',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On regroupe les médailles par régions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('region')['Medal'].count().nlargest(20).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien entendu, cela reflète souvent la puissance sportive et l'engagement des nations dans le sport de compétition au niveau international. Les USA dominent avec la Russie, l'Allemagne et l'Angleterre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour inclure uniquement l'année 2016\n",
    "medals_2016 = df[df['Year'] == 2016]\n",
    "\n",
    "# Identifier les dix équipes ayant remporté le plus de médailles en 2016\n",
    "top_10_teams_2016 = medals_2016.groupby('region')['Medal'].count().nlargest(10)\n",
    "\n",
    "# Filtrer les données pour inclure uniquement ces dix équipes\n",
    "filtered_df = df[df['region'].isin(top_10_teams_2016.index)]\n",
    "\n",
    "# Regrouper les données par année et par équipe, puis compter le nombre total de médailles par année et par équipe\n",
    "medals_by_year_and_team = filtered_df.groupby(['Year', 'region']).size().unstack(fill_value=0)\n",
    "\n",
    "# Tracer un graphique pour chaque équipe\n",
    "plt.figure(figsize=(12, 8))\n",
    "for team in medals_by_year_and_team.columns:\n",
    "    plt.plot(medals_by_year_and_team.index, medals_by_year_and_team[team], label=team)\n",
    "\n",
    "# Ajouter des étiquettes d'axe et un titre\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Medals')\n",
    "plt.title('Evolution of Medals for Top 10 Teams in 2016')\n",
    "\n",
    "# Ajouter une légende et afficher le graphique\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le nombres de médailles a connu de nombreuses disparités avant le 21ème siècle avec des écarts très important. \n",
    "Cependant cela tend à achanger à partir de 1996 envirion, voyons voir pourquoi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour inclure uniquement les années après 2000 et les Jeux Olympiques d'été\n",
    "medals_since_2000_summer = df[(df['Year'] >= 2000) & (df['Season'] == 'Summer')]\n",
    "\n",
    "# Identifier les dix équipes ayant remporté le plus de médailles après 2000\n",
    "top_10_teams_since_2000_summer = medals_since_2000_summer.groupby('region')['Medal'].count().nlargest(10).index\n",
    "\n",
    "# Filtrer les données pour inclure uniquement ces dix équipes\n",
    "filtered_df = df[(df['region'].isin(top_10_teams_since_2000_summer)) & (df['Season'] == 'Summer')]\n",
    "\n",
    "# Regrouper les données par année et par équipe, puis compter le nombre total de médailles par année et par équipe\n",
    "medals_by_year_and_team = filtered_df.groupby(['Year', 'region']).size().unstack(fill_value=0)\n",
    "\n",
    "# Tracer un graphique pour chaque équipe, en incluant uniquement les années après 2000\n",
    "plt.figure(figsize=(12, 8))\n",
    "for team in medals_by_year_and_team.columns:\n",
    "    plt.plot(medals_by_year_and_team.index[medals_by_year_and_team.index >= 2000], medals_by_year_and_team.loc[medals_by_year_and_team.index >= 2000, team], label=team)\n",
    "\n",
    "# Ajouter des étiquettes d'axe et un titre\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Medals')\n",
    "plt.title('Evolution of Medals for Top 10 Teams in Summer Olympics since 2000')\n",
    "\n",
    "# Ajouter une légende et afficher le graphique\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En 2008 la Chine passe devant les USA pour la première fois (Jo en CHine cet annéen là, d'ou l'importance du lieu)\n",
    "- le Japon connait une évolution net et positive\n",
    "- la Russie diminue logiquement de part le contexte politique\n",
    "- les UK dominent chez eux en 2012 avant de rechuter \n",
    "- les autres top pays sont relativement stables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons les équipes avec le plus fort taux d'évolution depuis 2000 pour comprendre quels sont les pays qui évoluent rapidement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour inclure uniquement les années 2000 et 2016\n",
    "medals_2000 = df[df['Year'] == 2000]\n",
    "medals_2016 = df[df['Year'] == 2016]\n",
    "\n",
    "# Regrouper les données par équipe et par année, puis compter le nombre total de médailles par équipe pour chaque année\n",
    "medals_by_team_2000 = medals_2000.groupby('region')['Medal'].count()\n",
    "medals_by_team_2016 = medals_2016.groupby('region')['Medal'].count()\n",
    "\n",
    "# Fusionner les deux séries de données pour comparer les médailles de 2000 et de 2016\n",
    "medals_comparison = pd.merge(medals_by_team_2000, medals_by_team_2016, on='region', suffixes=('_2000', '_2016'))\n",
    "\n",
    "# Remplacer les valeurs égales à 0 par 1 pour les équipes ayant 0 médaille en 2000 mais plus de 0 médaille en 2016\n",
    "medals_comparison['Medal_2000'].replace(0, 1, inplace=True)\n",
    "\n",
    "# Calculer le taux d'évolution en pourcentage\n",
    "medals_comparison['Evolution (%)'] = ((medals_comparison['Medal_2016'] - medals_comparison['Medal_2000']) / medals_comparison['Medal_2000']) * 100\n",
    "\n",
    "# Filtrer les équipes ayant plus que doublé leur nombre de médailles entre 2000 et 2016\n",
    "doubled_medals_teams = medals_comparison[medals_comparison['Medal_2016'] >= 2 * medals_comparison['Medal_2000']]\n",
    "\n",
    "# Filtrer les équipes ayant plus que doublé leur nombre de médailles entre 2000 et 2016 et ayant obtenu au moins une médaille en 2016\n",
    "doubled_medals_teams = doubled_medals_teams[doubled_medals_teams['Medal_2016'] > 0]\n",
    "\n",
    "# Trier les équipes en fonction de leur évolution du nombre de médailles en pourcentage (ordre décroissant)\n",
    "doubled_medals_teams_sorted = doubled_medals_teams.sort_values(by='Evolution (%)', ascending=False)\n",
    "\n",
    "# Afficher les équipes et leur nombre de médailles en 2000 et 2016, ainsi que le taux d'évolution en pourcentage\n",
    "print(\"Teams that more than doubled their number of medals between 2000 and 2016 and got at least one medal in 2016 (sorted by evolution percentage):\")\n",
    "print(doubled_medals_teams_sorted[['Medal_2000', 'Medal_2016', 'Evolution (%)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La croissance du nombre de médailles dans ces pays peut être attribuée à plusieurs facteurs potentiels. Tout d'abord, des investissements accrus dans le sport et le développement des infrastructures sportives pourraient avoir entraîné une amélioration des programmes de formation des athlètes et une augmentation du nombre de compétitions nationales et internationales auxquelles les athlètes ont pu participer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'analyse EDA suivante, nous utilisons un SimpleImputer KNeighborsClassifier pour simplifier l'analyse simplement, juste pour cette partie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation des valeurs manquantes avec la moyenne\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[['Age', 'Height', 'Weight']] = imputer.fit_transform(df[['Age', 'Height', 'Weight']])\n",
    "\n",
    "# Création du modèle KNN pour prédire le sexe en fonction de la taille et du poids\n",
    "knn_imputer = KNeighborsClassifier(n_neighbors=3)\n",
    "X_train = df.dropna(subset=['Sex'])[['Height', 'Weight']]\n",
    "y_train = df.dropna(subset=['Sex'])['Sex']\n",
    "knn_imputer.fit(X_train, y_train)\n",
    "\n",
    "# Remplissage des valeurs manquantes pour le sexe en utilisant le modèle KNN\n",
    "X_test = df[df['Sex'].isna()][['Height', 'Weight']]\n",
    "predicted_sex = knn_imputer.predict(X_test)\n",
    "df.loc[df['Sex'].isna(), 'Sex'] = predicted_sex\n",
    "\n",
    "# Affichage du DataFrame avec les valeurs manquantes remplies\n",
    "print(\"DataFrame with Missing Values Imputed:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne « notes » doit être supprimée car le nombre de zéros est supérieur à 50 %, donc peu utile en réalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('notes',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse physiologique des athlètes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour exclure les valeurs manquantes de la taille et du sexe\n",
    "filtered_df = df.dropna(subset=['Height', 'Sex', 'Year'])\n",
    "\n",
    "# Filtrer les données pour inclure uniquement les enregistrements avec le sexe Femme (F) ou Homme (M) et à partir de l'année 2000\n",
    "filtered_df = filtered_df[(filtered_df['Sex'].isin(['F', 'M'])) & (filtered_df['Year'] <= 2000)]\n",
    "\n",
    "# Tracer un boxplot pour l'évolution de la taille des hommes et des femmes depuis 2000\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Utiliser seaborn pour tracer le boxplot\n",
    "sns.boxplot(x='Year', y='Height', hue='Sex', data=filtered_df)\n",
    "\n",
    "# Ajouter des titres et des étiquettes d'axe\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Evolution of Height by Gender Since 2000')\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour exclure les valeurs manquantes de la taille et du sexe\n",
    "filtered_df = df.dropna(subset=['Height', 'Sex', 'Year'])\n",
    "\n",
    "# Filtrer les données pour inclure uniquement les enregistrements avec le sexe Femme (F) ou Homme (M) et à partir de l'année 2000\n",
    "filtered_df = filtered_df[(filtered_df['Sex'].isin(['F', 'M'])) & (filtered_df['Year'] >= 2000)]\n",
    "\n",
    "# Tracer un boxplot pour l'évolution de la taille des hommes et des femmes depuis 2000\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Utiliser seaborn pour tracer le boxplot\n",
    "sns.boxplot(x='Year', y='Height', hue='Sex', data=filtered_df)\n",
    "\n",
    "# Ajouter des titres et des étiquettes d'axe\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Height')\n",
    "plt.title('Evolution of Height by Gender Since 2000')\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe que la taille tend à légerement augmenter tout comme le poids\n",
    " \n",
    "- Les dsiciplines sont de plus en plus complexes et les caractériqtiques physique font la différence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x='Height',y='Weight',hue='Sex',data=df)\n",
    "plt.title('Height and weight for sex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beaucoup de valeurs aberrants\n",
    "- taille inférieur à 1.30m et supérieurs à 2.20m \n",
    "- Poids inférieur à 30Kg et supérieurs à 150Kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_medal=df.groupby('region')['Medal'].count().nlargest(20).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracer un barplot pour le nombre de médailles par région\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Utiliser seaborn pour tracer le barplot\n",
    "sns.barplot(y='region', x='Medal', data=region_medal, palette='viridis')  # Utilisation de la palette 'viridis'\n",
    "\n",
    "# Ajouter des titres et des étiquettes d'axe\n",
    "plt.title('Medals by Region')\n",
    "plt.xlabel('Number of Medals')\n",
    "plt.ylabel('Region')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_medal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sport'].value_counts(normalize='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season=df.groupby(['Year','Season','City'],as_index='False').first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution du nombres de médailles pour les Femmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "womenolympics = df[(df.Sex == 'F') & (df.Season == 'Summer')]\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.countplot(x='Year', data=womenolympics)\n",
    "plt.title('Women medals per edition of the Games')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une évoltuion presque éxponentielle depuis les années 80s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_medals=df.groupby(['region', 'Medal']).size().reset_index()\n",
    "summer_medals.columns=['region', 'Medal', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = summer_medals.pivot(index='region', columns='Medal', values='count')\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_medals_pivot = summer_medals.pivot_table(index='region', columns='Medal', values='count', fill_value=0)\n",
    "summer_medals_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_medals_20 = summer_medals.pivot_table(index='region', columns='Medal', values='count', fill_value=0).sort_values(['Gold'], ascending=False).head(20)\n",
    "summer_medals_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réorganiser les colonnes pour mettre Gold en premier\n",
    "summer_medals_20 = summer_medals_20[['Gold', 'Silver', 'Bronze']]\n",
    "\n",
    "# Définir les couleurs correspondantes\n",
    "colors = ['#FFD700', '#C0C0C0', '#CD7F32']\n",
    "\n",
    "# Tracer le graphique à barres avec les couleurs correspondantes\n",
    "summer_medals_20.plot(kind='bar', color=colors)\n",
    "plt.xlabel('Country')\n",
    "plt.title('Medals by Country - Summer Olympics')\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_sex_medal=df.groupby(['Year', 'Sex'])['Medal'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_sex_medal_pivot=year_sex_medal.pivot(index='Year', columns='Sex', values='Medal').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure pour le graphique avec une taille personnalisée\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Tracer le graphique en utilisant la méthode plot de Pandas\n",
    "# Utiliser 'line' pour un graphique en ligne\n",
    "year_sex_medal_pivot.plot(kind='line')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of participants')\n",
    "plt.title('Number of participants by year and gender')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis le 21ème siècle, la parité tend à être respécté, la place des femmes est importante dans le sport et de plus en plus médiatisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure pour le graphique avec une taille personnalisée\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Utiliser la méthode countplot de Seaborn pour tracer le graphique\n",
    "# 'Year' comme axe des x, 'Sex' comme hue pour différencier les sexes, et les données sont fournies par le DataFrame df\n",
    "sns.countplot(x='Year', hue='Sex', data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Female and Male Participants per Year')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien ententu leur parts ont seouvent été inférieur à celle des hommes, sauf depuis 2020 ou cela tend à être du 50/50 envirion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport=df['Sport'].value_counts()[:5]\n",
    "print(sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport_summer=df[df['Season']=='Summer']['Sport'].value_counts().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant on regarde avec un type boîte à moustaches pour illustrer la variation de l'âge des athlètes participant aux Jeux olympiques au fil des années. Il permet d'observer les différences d'âge médian et la dispersion des âges des participants pour chaque année."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une figure pour le graphique avec une taille personnalisée\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "# Utiliser la méthode boxplot de Seaborn pour tracer le graphique\n",
    "# 'Year' comme axe des x, 'Age' comme axe des y, et les données sont fournies par le DataFrame df\n",
    "sns.boxplot(x='Year', y='Age', data=df)\n",
    "\n",
    "# Ajouter un titre au graphique\n",
    "plt.title('Variation of Age for Athletes')\n",
    "\n",
    "# Afficher le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sport=df['Sport'].value_counts()[:5]\n",
    "print(sport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Utilisation directe de sport.index et sport.values dans plt.pie()\n",
    "plt.pie(sport.values, labels=sport.index, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "plt.title('Répartition des sports')\n",
    "plt.axis('equal')  # Assure que le graphique est circulaire\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** : L'athlétisme, en tant que sport emblématique, est placé en tête, suivi de près par la gymnastique et la natation, tous deux très médiatisés et appréciés. Le tir et le cyclisme complètent la liste, reflétant leur longue tradition olympique et leur engagement continu des athlètes et des fans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la figure pour le graphique avec une taille personnalisée\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Utilisation de sns.barplot pour tracer le graphique à barres\n",
    "# y représente les sports, x représente le nombre d'événements, palette='magma' définit la palette de couleurs\n",
    "sns.barplot(y=sport_summer.index, x=sport_summer.values, palette='viridis')\n",
    "\n",
    "plt.xlabel('Number of events')\n",
    "plt.ylabel('Sport')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Number of events in each sport in the summer Olympics\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les participations des pays au JO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.groupby('Year')['region'].nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.barplot(x='Year', y='region', data=df2)\n",
    "plt.title('How many countries attend each year')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Number of regions')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis 1994, le nombres de pays tend à se stabiliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python profiling report\n",
    "# profile = ProfileReport(df, title='Pandas Profiling Report')\n",
    "# profile.to_file(\"report-profiling-test.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot_ui(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAITER AGE GROUP\n",
    "df['AgeGroup'] = pd.cut(df.Age, bins=range(0, 81, 10), right=True)\n",
    "\n",
    "# TRAITER WEIGHT GROUP\n",
    "df['WeightGroup'] = pd.cut(df.Weight, bins=range(0, 215, 20), right=True)\n",
    "\n",
    "# TRAITER HEIGHT GROUP\n",
    "df['HeightGroup'] = pd.cut(df.Height, bins=range(100, 227, 20), right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ['Sex', 'AgeGroup', 'HeightGroup', 'WeightGroup'] # attrs permet de sélectionner les colonnes à afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres de style de Seaborn\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Créer la figure\n",
    "figure = plt.figure(figsize=(14, 10))\n",
    "figure.suptitle('Répartition des médailles dans les Jeux Olympiques', fontsize=16)\n",
    "\n",
    "# Ajuster l'espacement entre les sous-graphiques\n",
    "plt.subplots_adjust(top=0.9, bottom=0.1, hspace=0.5, wspace=0.4)\n",
    "\n",
    "# Boucle sur les attributs pour créer les sous-graphiques\n",
    "for i, col in enumerate(attrs):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    plt.xticks(rotation=40, ha='right')  # Rotation des étiquettes sur l'axe des x\n",
    "    sns.countplot(x=col, hue='Medal', data=df, palette='pastel')  # Utiliser une palette de couleurs pastel\n",
    "    plt.title('Répartition des médailles par ' + col)  # Titre du sous-graphique\n",
    "\n",
    "# Améliorer la disposition des sous-graphiques\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion** \n",
    "- L'âge est peut-être  un prédicteur fort de la victoire en médaille pour les athlètes, mais d'autres facteurs peuvent influencer les performances olympiques aussi\n",
    "- importante inégalité entre les sexes dans les Jeux olympiques tout au long des 120 années soulignant un domaine où des progrès sont nécessaires (mais presque paritaire depuis cette année 2024)\n",
    "- Les variables biologiques telles que lâge, le poids et la taille  sont certainement importantes pour prédire la probabilité de remporter une médaille\n",
    "- impact de lâge sur les performances sportives varie, avec des différences observées entre les athlètes individuels et les médaillés \n",
    "- une domination et un top 2 toujours identique, le top 10 lui varie d'une édition à une autre mais gloablement identique \n",
    "- des pays avec une forte évolution du nombres de médailles existe, ce qui peux compliqué la prédiciton pouir l'ensemble de ces pays à fort évoluiton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Récupération de données supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pays organisateurs à partir des années 1948"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scrapping de Wikipédia\n",
    "url_host_citi='https://en.wikipedia.org/wiki/List_of_Olympic_Games_host_cities'\n",
    "response_2=requests.get(url_host_citi)\n",
    "soup_2=BeautifulSoup(response_2.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Récupération des éléments de la page\n",
    "L_pays_1896=[]\n",
    "L_pays_1948=[]\n",
    "L_pays_2000=[]\n",
    "L_pays=[]\n",
    "\n",
    "elements=soup_2.findAll('span',class_='datasortkey')\n",
    "\n",
    "for element in elements:\n",
    "    pays=element.find('a').text\n",
    "    L_pays.append(pays)\n",
    "L_pays_1896=L_pays[:7]\n",
    "L_pays_1948=L_pays[14:42]\n",
    "L_pays_2000=L_pays[42:58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On enlève la Norvège qui a organisé la même année en 1992 des jeux d'hiver tandis qu'en Espagne se sont déroulés les jeux d'été.\n",
    "Puis la Suède qui a organisé des jeux d'été la même année 1956 que l'Australie , c'est un choix de notre part pour la construction de notre variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L_pays_1948.pop(6)\n",
    "L_pays_1948.pop(-3)\n",
    "\n",
    "L_annees_1948=[1948+ i for i in range(0,52,2)]\n",
    "\n",
    "# Itération des années\n",
    "L_annees_2000=[2000 + i  for i in range(0,34,2)]\n",
    "L_annees_2000.pop(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On lie les pays et les années\n",
    "L_pays_annee=[]\n",
    "for i in range(len(L_pays_1948)):\n",
    "    L_pays_annee.append((L_pays_1948[i],L_annees_1948[i]))\n",
    "\n",
    "for i in range(len(L_pays_2000)):\n",
    "    L_pays_annee.append((L_pays_2000[i],L_annees_2000[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remplacement à effectuer pour conserver les mêmes données que pour la suite \n",
    "# On fait le choix d'assigner la Yougoslavie au Monténégro\n",
    "\n",
    "to_replace = {\n",
    "    'Yugoslavia' :'Montenegro',\n",
    "    'Soviet Union' : 'Russia',\n",
    "     'West Germany' : 'Germany', \n",
    "    'South Korea':'Korea, South'\n",
    "} \n",
    "\n",
    "L_pays_annee = [(to_replace.get(country, country), year) for country, year in L_pays_annee]\n",
    "\n",
    "# Pour vérifier plus tard la présence des pays hôtes dans la table de correspondance précédemment créée\n",
    "countries_to_test = [t[0] for t in L_pays_annee]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pays avec un passé communiste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Scrapping d'une page Wikipédia listant les pays communistes\n",
    "url_soviet='https://en.wikipedia.org/wiki/Post-Soviet_states'\n",
    "response_soviet=requests.get(url_soviet)\n",
    "soup_soviet=BeautifulSoup(response_soviet.text,'html.parser')\n",
    "\n",
    "L_pays_soviet=[]\n",
    "\n",
    "pays_soviet=soup_soviet.findAll('b')\n",
    "#print(pays_soviet)\n",
    "for pays in pays_soviet:\n",
    "    b=pays.find('a')\n",
    "    if b is not None:\n",
    "        L_pays_soviet.append(b.text)\n",
    "L_pays_soviet=L_pays_soviet[:15]\n",
    "\n",
    "complete_urss_regime=lambda x : 1 if x in L_pays_soviet else 0\n",
    "L_pays_soviet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Création d'un dataframe\n",
    "df_hote=pd.DataFrame(L_pays_annee,columns=['Host_country','Year'])\n",
    "df_hote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### JO de Tokyo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Pour les jeux de 2020 (été, Tokyo), nous avons trouvé le dataset suivant : https://www.kaggle.com/datasets/piterfm/tokyo-2020-olympics. Après téléchargement des différents datasets, nous le plaçons dans `./data/additionnal/tokyo2020`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Chargement des données\n",
    "df_tokyo_athletes = pd.read_csv('data/additionnal/tokyo2020/athletes.csv')\n",
    "df_tokyo_medals = pd.read_csv('data/additionnal/tokyo2020/medals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Création d'un dataframe avec les même colonnes que df_athlete\n",
    "df_complete_tokyo2020 = pd.DataFrame(columns=df_athlete.columns)\n",
    "\n",
    "# On s'assure qu'il n'y a pas de doublons\n",
    "df_tokyo_athletes.drop_duplicates(inplace=True)\n",
    "\n",
    "df_merged_bis = pd.merge(df_tokyo_athletes, df_tokyo_medals, how='left', left_on=['name', 'discipline_code'], right_on=['athlete_name', 'discipline_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "athletes_to_be_added = []\n",
    "# Itération dans df_tokyo_athletes pour ajouter dans athletes_to_be_added, qui sera ensuite ajouté au dataframe df_complete_tokyo2020\n",
    "\n",
    "for index, row in df_tokyo_athletes.iterrows():\n",
    "    athlete_name = row['name']\n",
    "    athlete_sex = str(row['gender'])[0] if type(row['gender'] != float) else np.nan\n",
    "    athlete_age = (2021 - datetime.date.fromisoformat(str(row['birth_date'])).year) if (type(row['birth_date'] == str) and str(row['birth_date']).lower() != 'nan' ) else np.nan\n",
    "    athlete_height_in_m = (int(float(row['height_m/ft'].split('/')[0]) *100)) if (type(row['height_m/ft']) != float) else np.nan\n",
    "    athlete_team = row['country']\n",
    "    athlete_noc = row['country_code']\n",
    "    athlete_games = 'Tokyo 2020'\n",
    "    athlete_year = 2020\n",
    "    athlete_season = 'Summer'\n",
    "    athlete_city = 'Tokyo'\n",
    "    athlete_discipline = row['discipline']\n",
    "    athletes_to_be_added.append({\n",
    "        'Name': athlete_name,\n",
    "        'Sex': athlete_sex, \n",
    "        'Age': athlete_age,\n",
    "        'Height': athlete_height_in_m,\n",
    "        'Team': athlete_team,\n",
    "        'NOC': athlete_noc,\n",
    "        'Games': athlete_games,\n",
    "        'Year': athlete_year,\n",
    "        'Season': athlete_season,\n",
    "        'City': athlete_city,\n",
    "        'Sport': athlete_discipline,\n",
    "    })\n",
    "\n",
    "df_complete_tokyo2020 = df_complete_tokyo2020.from_records(athletes_to_be_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On effectue une jointure droite entre les deux dataframes, de manière à conserver seulement les athlètes avec différentes médailles dans différentes disciplines\n",
    "df_merged = pd.merge(df_complete_tokyo2020, df_tokyo_medals, left_on=['Name', 'Sport'], right_on=['athlete_name', 'discipline'], how='left')\n",
    "df_merged.drop(columns=['medal_code', 'medal_date', 'athlete_short_name',\n",
    "       'athlete_name', 'athlete_sex', 'athlete_link', 'country_code',\n",
    "       'discipline_code', 'country', 'discipline'], inplace=True)\n",
    "\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "\n",
    "df_merged['medal_type'] = df_merged['medal_type'].apply(lambda x: x.replace('Medal', '').strip() if type(x) != float else x)\n",
    "df_merged.rename(columns={'medal_type': 'Medal', 'event': 'Event'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On remplace les valeurs 'n' en NaN pour le sexe\n",
    "df_merged['Sex'] = df_merged['Sex'].apply(lambda x: np.NAN if x == 'n' else x)\n",
    "\n",
    "# On merge avec df_athlete\n",
    "df_athlete = pd.concat([df_athlete,df_merged])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Statistiques provenant de la Banque Mondiale\n",
    "Les noms de code des pays ne sont pas équivalents aux NOC. On scrappe donc des données externes pour relier les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# URL of the webpage containing the table\n",
    "url = \"https://www.iban.com/country-codes\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract data from the table\n",
    "    data = []\n",
    "    table = soup.find('table', class_='table table-bordered downloads tablesorter')\n",
    "    for row in table.find_all('tr')[1:]:\n",
    "        country = row.find_all('td')[0].text.strip()\n",
    "        alpha_3 = row.find_all('td')[2].text.strip()\n",
    "        data.append({'Country': country, 'Alpha-3 code': alpha_3})\n",
    "    \n",
    "    # Create a DataFrame\n",
    "    df_countries_corresp = pd.DataFrame(data)\n",
    "    print(df_countries_corresp)\n",
    "else:\n",
    "    print(\"Failed to retrieve the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Fonction pour fusionner les données de la table de correspondance scrappée précédemment et les données récupérées au moyen de l'API de la banque mondiale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_data_with_correspond_table(df, df_correspond_table, left_on, right_on):\n",
    "    df.reset_index()\n",
    "    merged = df.merge(df_correspond_table, left_on=left_on, right_on=right_on, how='inner')\n",
    "    merged_columns = list(df_correspond_table.columns)  # Specify the merged columns\n",
    "    other_columns = [col for col in merged.columns if col not in merged_columns]  # Get other columns\n",
    "    reordered_columns = merged_columns + other_columns  # Concatenate merged columns and other columns\n",
    "    merged = merged[reordered_columns]\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Ajout du GDP à partir des données de la Banque Mondiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s=wb.search('GDP current') \n",
    "gdp=wb.data.DataFrame('NY.GDP.MKTP.CD').transpose()\n",
    "df_gdp=pd.DataFrame(gdp)\n",
    "df_gdp = df_gdp.transpose()\n",
    "df_gdp.columns = [col.strip('YR') for col in df_gdp.columns]\n",
    "df_gdp.reset_index(inplace=True)\n",
    "#df_gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fusion avec la table de correspondance pour récupérer les bons noms des pays\n",
    "gdp_country = merge_data_with_correspond_table(df_gdp, df_countries_corresp, 'economy', 'Alpha-3 code')\n",
    "gdp_country.drop(columns=['Alpha-3 code'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Préparation du dataframe pour sa future fusion avec les autres données\n",
    "years_cols=[col for col in df_gdp.columns if col.isdigit()]\n",
    "df_melted_gdp = pd.melt(gdp_country, id_vars=['Country'], value_vars=years_cols, var_name='Year', value_name='GDP')\n",
    "# Convertir la colonne Year en type int\n",
    "df_melted_gdp['Year'] = df_melted_gdp['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_melted_gdp = df_melted_gdp[df_melted_gdp['Year'] >= START_YEAR] "
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Ajout de la population à partir des données de la Banque Mondiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "population=wb.data.DataFrame('SP.POP.TOTL').transpose()\n",
    "df_population=pd.DataFrame(population)\n",
    "df_population = df_population.transpose()\n",
    "df_population.columns = [col.strip('YR') for col in df_population.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On fusionne les données avec la table de correspondance\n",
    "pop_country = merge_data_with_correspond_table(df_population, df_countries_corresp, 'economy', 'Alpha-3 code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years_cols=[col for col in df_population.columns if col.isdigit()]\n",
    "df_melted_population = pd.melt(pop_country, id_vars=['Country'], value_vars=years_cols, \n",
    "                               var_name='Year', value_name='Population')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_melted_population.isna().sum()\n",
    "# Il y a quelques valeurs nulles, on va les fill un peu plus tard avec un KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convertir la colonne Year en type int\n",
    "df_melted_population['Year'] = df_melted_population['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On merge les deux dataframes créés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_gdp_df = df_melted_population.merge(df_melted_gdp, how='inner', on=['Country', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Calcul du GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pop_gdp_df['GDP_per_capita'] = pop_gdp_df['GDP'] / pop_gdp_df['Population']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On conserve seulement le GDP per capita.\n",
    "pop_gdp_df.drop(columns=['GDP'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Ajout de la population urbaine à partir des données de la Banque Mondiale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_urban_pop=wb.search('Urban population')\n",
    "urban_population=wb.data.DataFrame('SP.URB.TOTL.IN.ZS').transpose()\n",
    "df_urban_population=pd.DataFrame(urban_population)\n",
    "df_urban_population = df_urban_population.transpose()\n",
    "df_urban_population.columns = [col.strip('YR') for col in df_urban_population.columns]\n",
    "\n",
    "df_urban_population=df_urban_population.reset_index()\n",
    "\n",
    "urban_pop_country = merge_data_with_correspond_table(df_urban_population, df_countries_corresp, 'economy', 'Alpha-3 code')\n",
    "urban_pop_country.drop(columns=['Alpha-3 code'], inplace=True)\n",
    "\n",
    "years_cols=[col for col in urban_pop_country.columns if col.isdigit()]\n",
    "df_melted_urban_population = pd.melt(urban_pop_country, id_vars=['Country'], value_vars=years_cols, \n",
    "                               var_name='Year', value_name='Urban Population')\n",
    "\n",
    "df_melted_urban_population['Year'] = df_melted_urban_population['Year'].astype(int)\n",
    "\n",
    "df_melted_urban_population=df_melted_urban_population.rename(columns={'Urban Population':\"Urban Population(%)\"})\n",
    "\n",
    "df_melted_urban_population['Urban Population(%)'] = df_melted_urban_population['Urban Population(%)'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On merge avec GDP_per_capita et population\n",
    "pop_gdp_df = pop_gdp_df.merge(df_melted_urban_population, how='inner', on=['Country', 'Year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On ne conserve que les données des années correspondant aux JO d'été"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdp_per_capita_filtered = pop_gdp_df[pop_gdp_df['Year'].isin(L_annees_1948 + L_annees_2000)]\n",
    "gdp_per_capita_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gdp_per_capita_filtered.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optimisation des datasets\n",
    "   Dans un souci d'optimisation de l'espace mémoire occupé, nous allons faire en sorte d'optimiser les différents dataframe que nous utilisons. \n",
    "Pour mener à bien ceci, nous allons des fonctions contenues dans `describe_csv.py`, en les améliorant pour automatiser le processus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_athlete.info(memory_usage='deep', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Jusqu'à maintenant, nous utilisons le dataframe df_athlete. Nous allons définir différentes fonctions pour optimiser les types et ainsi optimiser l'espace mémoire occupé. Cette fonction a été conçue de manière à être réutilisée au fur et à mesure de la progression du df\n",
    "\n",
    "def define_and_use_optimal_type(df:pd.DataFrame):\n",
    "    for column in df.columns:\n",
    "        if(is_numeric_dtype(df[column]) == True):\n",
    "            # Set optimal type else do nothing\n",
    "            optimalype = optimal_type(df[column], df[column].min(), df[column].max())\n",
    "            try: \n",
    "                df[column] = df[column].astype(optimalype)\n",
    "            except:\n",
    "                print(\"error converting {}\".format(column))\n",
    "        if(is_object_dtype(df[column]) == True):\n",
    "            # Ensure different modalities\n",
    "            unique_values = len(df[column].unique())\n",
    "            if unique_values < 1500: # given the current dataframe size, we assume that 1500 different values maximum could be converted as categories. AS an example there are 1000+ different events\n",
    "                df[column] = df[column].astype('category') \n",
    "            \n",
    "    return df\n",
    "\n",
    "df_athlete = define_and_use_optimal_type(df_athlete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_athlete.info(memory_usage='deep', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_athlete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO : à voi / retrait des données dupliquées\n",
    "df_athlete.drop_duplicates(subset=['Name', 'Year', 'Age', 'Team', 'Medal', 'Event', 'Sport', 'Sex'])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Nettoyage des données et aggrégations diverses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataframe dictionnary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dictionnary=pd.read_csv('data/dictionary.csv')\n",
    "df_dictionnary=df_dictionnary.rename(columns={'GDP per Capita':'PIB/habitant','Code':'NOC'})\n",
    "print(df_dictionnary.isna().sum())\n",
    "# Nous retirons toutes les variables suivantes, dans la mesure où nous les avons déjà récupérées\n",
    "df_dictionnary.drop(['Population', 'PIB/habitant'],axis=1, inplace=True)\n",
    "print(df_dictionnary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Dataframe région"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_region=df_region.rename(columns={'region':'Country'})\n",
    "df_region[df_region['Country'].isnull()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On retire les réfugiés\n",
    "df_region = df_region.query(\" NOC != 'ROT' and NOC != 'UNK' \")\n",
    "\n",
    "# Ajout des îles Tuvalu comme ce sont les seules \n",
    "df_region[('Country')] = df_region['Country'].fillna('Tuvalu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Merge des dataframes et traitement des valeurs nulles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Création d'une table de correspondance et application de cette dernière\n",
    "Ici, on cherche à créer une table de correspondance entre les pays contenus dans les données de la banque mondiale, et les pays contenus dans le dataframe. En effet, le 'code pays' contenu dans la base de données de la banque mondiale et les NOC ne sont pas toujours similaires.Voici l'idée de process ;  \n",
    "1- On retire les stopwords, les accents, la ponctuation et les double espaces générés dans chacun des dataframes, pour ensuite grouper la majorité des pays sur la colonne commune Country_clean créée. \n",
    "2- Comme quelques NOC et codes pays sont tout de même similaires, on essaye de grouper les données manquantes d'une part et d'autre en les utilisant. On sépare donc le dataframe en deux, puis on regroupe\n",
    "3- Etant donné qu'il ne reste pas beaucoup de pays manquants (25), on choisit ici de finir de les grouper à la main. Ceci est d'autant plus pertinent que tous les pays issus des données de la banque mondiale ne concourent pas nécessairement aux JO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On commence donc par le nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fonction à appliquer aux dataframes pour le nettoyage \n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove accented characters\n",
    "    text_no_accents = unidecode.unidecode(text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = nltk.word_tokenize(text_no_accents.lower())  # Convert to lowercase\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words_filtered = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Remove punctuation, parentheses, and other non-alphanumeric characters\n",
    "    words_filtered = [re.sub(r'[^a-zA-Z0-9\\s]', '', word) for word in words_filtered]\n",
    "    \n",
    "    # Remove two or more consecutive spaces\n",
    "    text_filtered = re.sub(r'\\s{2,}', ' ', ' '.join(words_filtered)).strip()\n",
    "    \n",
    "    # Replace everything between words with one space only\n",
    "    text_cleaned = re.sub(r'\\b\\w+\\b', lambda m: m.group(0).replace(\" \", \"\"), text_filtered)\n",
    "    \n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Application du traitement de nettoyage du nom des pays et retrait des colonnes dont nous ne nous servirons pas sur le df_dictionnary, précédemment chargé (mis à dispo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dictionnary['Country_clean'] = df_dictionnary['Country'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On applique également le traitement de nettoyage du nom des pays sur les données scrappées sur le site de l'IBAN (qui nous donne la correspondance Alpha-3 code / Pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_countries_corresp['Country_clean'] = df_countries_corresp['Country'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On tente un premier merge sur les colonnes nettoyées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_merge_2 = df_dictionnary.merge(df_countries_corresp, how='outer', left_on='Country_clean', right_on=\"Country_clean\")\n",
    "test_merge_2.rename(columns={'Country_x':'Country_df_dict', 'Country_y': 'Country_df_iban', 'Code': 'NOC'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On split l'aggrégation en deux : d'une part, on garde les pays complets, et de l'autres, on reprend les pays incomplets (que nous allons traiter par la suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uncomplete_countries = (test_merge_2[test_merge_2.isnull().any(axis=1) == True])\n",
    "complete_countries =  (test_merge_2[test_merge_2.isnull().any(axis=1) == False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On sépare le dataframe des lignes incomplètes, afin de pouvoir ensuite faire une tentative de merge en utilisant le NOC / Alpha-3 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Séparation en deux dataframes\n",
    "df_noc = uncomplete_countries[['Country_df_dict', 'NOC', 'Country_clean']]\n",
    "df_alpha_3 = uncomplete_countries[['Country_df_iban', 'Alpha-3 code', 'Country_clean']]\n",
    "\n",
    "test_merge = df_noc.merge(df_alpha_3, how='inner', left_on='NOC', right_on='Alpha-3 code')\n",
    "\n",
    "merged_noc_alpha_code = test_merge[test_merge['NOC'] == test_merge['Alpha-3 code']]\n",
    "merged_noc_alpha_code.drop(columns=['Country_clean_y'], inplace=True)\n",
    "merged_noc_alpha_code.rename(columns={'Country_clean_x' : 'Country_clean'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Après le traitement, on ajoute un dataframe des données étant presque complètes, puis on applique un traitement sur le nom des pays afin de retirer les astérisques résiduelles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries_almost_complete = pd.concat([complete_countries, merged_noc_alpha_code])\n",
    "countries_almost_complete.drop(columns=['Alpha-3 code'], inplace=True)\n",
    "countries_almost_complete['Country_df_dict'] = countries_almost_complete['Country_df_dict'].str.replace('*', '', regex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On termine suite de compléter les correspondances, complétées à la main au vu du faible nombre de pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_corresp = {\n",
    "    'Country_df_dict': ['Palestine, Occupied Territories', 'Brunei', 'Iran', 'Kiribati', 'Marshall Islands', 'Montenegro','South Sudan', 'Tanzania', 'Tuvalu', 'Vietnam', 'British Virgin Islands', 'Virgin Islands' ],\n",
    "    'Country_df_iban': ['Palestine, State of', 'Brunei Darussalam', 'Iran (Islamic Republic of)', 'Kiribati', 'Marshall Islands (the)', 'Montenegro', 'South Sudan', 'Tanzania, United Republic of','Tuvalu', 'Viet Nam',  'Virgin Islands (British)','Virgin Islands (U.S.)'],\n",
    "}\n",
    "\n",
    "hand_correspondance = pd.DataFrame.from_dict(last_corresp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Enfin, on assemble ces correspondances écrites à la main avec celles déterminées précédemment. On retire les colonnes qui ne nous intéressent pas (NOC et Country_clean), et on exporte un fichier csv au propre. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countries_complete = pd.concat([hand_correspondance, countries_almost_complete])\n",
    "countries_complete.drop(columns=['NOC', 'Country_clean'], inplace=True)\n",
    "countries_complete = define_and_use_optimal_type(countries_complete)\n",
    "countries_complete.to_csv('data/mapping_countries_dictionnary_worldbank.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On vérifie s'il y a des pays qui ne correspondent pas pour l'attribution de la variable is_soviet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_missing_elements_from_list(list, list_to_check_in):\n",
    "    set_L_pays_soviet = set(list)\n",
    "    set_another_list = set(list_to_check_in)\n",
    "    \n",
    "    # Find elements from L_pays_soviet that are missing in another_list\n",
    "    missing_elements = set_L_pays_soviet - set_another_list\n",
    "    \n",
    "    # Print the missing elements\n",
    "    if missing_elements:\n",
    "        print(\"Missing elements from L_pays_soviet in another_list:\")\n",
    "        for element in missing_elements:\n",
    "            print(element)\n",
    "    else:\n",
    "        print(\"No missing elements from L_pays_soviet in another_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_missing_elements_from_list(L_pays_soviet, list(countries_complete.Country_df_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On fait pareil avec les pays hôtes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_missing_elements_from_list(countries_to_test, list(countries_complete.Country_df_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Enfin, on procède au remplacement des valeurs dans le dataframe contenant le GDP per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On replace les valeurs des pays par les valeurs des pays incluses dans le dataframe\n",
    "replace_dict = countries_complete.set_index('Country_df_iban')['Country_df_dict'].to_dict()\n",
    "pop_gdp_df['Country'] = pop_gdp_df['Country'].replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On vérifie les valeurs manquantes\n",
    "values_not_in_df2 = pop_gdp_df[~pop_gdp_df['Country'].isin(countries_complete['Country_df_dict'])]\n",
    "values_not_in_df2['Country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Après recherche, il semblerait que ces pays ne soient pas compris dans les pays compétiteurs. Nous pouvons donc les ignorer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Opérations sur les pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_region.drop(columns=['notes'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_dictionnary.drop(columns=['Country_clean'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_complete=pd.merge(pd.merge(df_athlete,df_region,on='NOC',how='left'),df_dictionnary,on='NOC',how='left')\n",
    "\n",
    "# On prend seulement les JO d'été\n",
    "df_complete=df_complete[df_complete['Season']=='Summer']\n",
    "df_complete=df_complete[df_complete['Year'] >= START_YEAR] # TODO: Quelle année??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attribution des pays en fonction des NOC \n",
    "df_complete=pd.merge(df_complete,df_region,on='NOC',how='left')\n",
    "# Fill missing values in 'Country_y' with values from 'Country_x'\n",
    "df_complete['Country'] = df_complete['Country_y']\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_complete.drop(['Country_x', 'Country_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On retire les NOC (réfugiés)\n",
    "df_complete=df_complete.query(\" NOC !='ROC' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyse des valeurs nulles \n",
    "df_complete.isna().sum()\n",
    "# 156 sports où on sait pas ce que c'est .... et des country (26 221) qui ne sont pas attribués non plus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attribution des intitulés de pays manquants\n",
    "liste_pays=df_region['Country'].tolist()\n",
    "liste_NOC=df_region['NOC'].tolist()\n",
    "\n",
    "dictio_NOC_pays=dict(zip(liste_NOC,liste_pays))\n",
    "\n",
    "dictio_NOC_pays['SGP']='Singapour'\n",
    "dictio_NOC_pays['LBN']='Liban'\n",
    "\n",
    "df_complete['Country']=df_complete['Country'].fillna(df_complete['NOC'].map(dictio_NOC_pays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Il y a quatre NOC qui ne correspondent à aucun pays dans notre EOR : réfugiés , ROT réfugiés aussi , LBN c'est le Liban (Lebanon en anglais )\n",
    "df_complete=df_complete.query(\" NOC !='ROT' and NOC !='EOR' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On ajoute les pays organisateurs pour chaque ligne scrappée précédemment\n",
    "df_complete=pd.merge(df_complete,df_hote,on='Year',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On ajoute une colonne booléenne (l'athlète participe aux jeux dans son propre pays)\n",
    "compare_col=lambda x : 1 if x['Country']==x['Host_country'] else 0 \n",
    "df_complete['Participation_own_country']=df_complete.apply(compare_col,axis=1)\n",
    "df_complete[df_complete['Participation_own_country']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On récupère les pays communistes scrappés précédemment\n",
    "df_complete['Soviet_past']=df_complete['Country'].apply(complete_urss_regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On renomme les pays pour pouvoir merge avec les données scrappées \n",
    "# Changement de noms pour les pays, on retire les astérisques\n",
    "df_complete['Country'] = df_complete['Country'].str.replace('*', '', regex=False)\n",
    "\n",
    "df_complete['Country']=df_complete['Country'].replace('Singapour','Singapore')\n",
    "df_complete['Country']=df_complete['Country'].replace('East Timor (TimorLeste)','East Timor (Timor-Leste)')\n",
    "df_complete['Country']=df_complete['Country'].replace('GuineaBissau','Guinea-Bissau')\n",
    "df_complete['Country']=df_complete['Country'].replace('Liban','Lebanon')\n",
    "df_complete['Country']=df_complete['Country'].replace('Trinidad','Trinidad and Tobago')\n",
    "\n",
    "# Birmanie / Myanmar\n",
    "df_complete['Country']=df_complete['Country'].replace('Burma','Myanmar')\n",
    "\n",
    "# On retire les individuals comme on ne peut pas mapper de PIB dessus \n",
    "df_complete = df_complete[df_complete['Country'] != 'Individual Olympic Athletes']\n",
    "\n",
    "\n",
    "# Traitement des données particulières\n",
    "# URSS \n",
    "df_complete.loc[(df_complete['Team'] == 'Soviet Union') & (df_complete['NOC'] == 'URS'), ['Team', 'NOC', 'Country']] = ['Russia', 'RUS', 'Russia'] # URSS période 1952-1988\n",
    "\n",
    "# GERMANY\n",
    "df_complete.loc[(df_complete['Team'] == 'East Germany') & (df_complete['NOC'] == 'GDR'), ['Team', 'NOC', 'Country']] = ['Germany', 'GER', 'Germany']\n",
    "\n",
    "# CHINA\n",
    "df_complete.loc[df_complete['Team'] == \"People's Republic of China\", ['Team', 'NOC', 'Country']] = ['China', 'CHN', 'China']\n",
    "\n",
    "# UNITED STATES\n",
    "df_complete.loc[df_complete['Team'] == \"United States of America\", ['Team', 'NOC', 'Country']] = ['United States', 'USA', 'United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Normalisation des pays. Certains sont écrits avec des suffixes (Ex: Brazil-1, Brazil-2)\n",
    "replacement_dict = {}\n",
    "\n",
    "old_countries_to_process = df_complete.Country.unique()\n",
    "\n",
    "for i in old_countries_to_process:\n",
    "    # Check if the element is a string or bytes-like object\n",
    "    if isinstance(i, str):\n",
    "        # Perform the replacement and add to the replacement dictionary\n",
    "        replacement_dict[i] = re.sub(r'-\\d+', '', i)\n",
    "    else:\n",
    "        # If the element is not a string, handle the case accordingly\n",
    "        # For example, you can choose to skip it or handle it differently\n",
    "        print(f\"Skipping non-string element: {i}\") # should not be NaN but anyway\n",
    "\n",
    "df_complete = df_complete.replace({\"Country\": replacement_dict})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "final_df_countries = set((df_complete.Country.dropna()).to_frame().Country.unique())\n",
    "gdp_df_countries = set(pop_gdp_df['Country'].unique())\n",
    "\n",
    "not_common_elements = gdp_df_countries.symmetric_difference(final_df_countries)\n",
    "print(not_common_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Suite à ces tests, \n",
    "- On retire les pays qui ne figurent pas au sein des données de la Banque Mondiale. Après vérification, il s'agit de pays représentant une place assez négligeable dans la sphère olympique. De plus, certains (Netherland Antilles) ne participent plus aux JO. Enfin, cela ne représente que 3 pays sur un total de plus de 200 pays, ce qui est négligeable pour l'entraînement du modèle. Les voici: Kosovo, Taiwan, Cook Islands, Netherland Antilles.\n",
    "- Des données ont été modifiées dans le mapping des pays ci-dessous car ils étaient parfois écrits de plusieurs manières différentes (la Birmanie —Burma— a changé de nom par exemple. Ou encore East Timor (Timor-Leste) était parfois écrit East Timor (TimorLeste).\n",
    "- On retire tous les athlètes ayant pour mention 'Individual Olympic Athletes', car on ne peut pas leur attribuer de PIB\n",
    "\n",
    "Pour le reste des pays mentionnés dans cette liste, il ne s'agit pas de pays ayant participé aux JO. Nous les ignorons donc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Opérations sur le sexe, le poids et les tailles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_male = df_complete[df_complete['Sex'] == 'M']\n",
    "df_female = df_complete[df_complete['Sex'] == 'F']\n",
    "columns_to_impute = ['Age', 'Height', 'Weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Si le fichier df_complete_entire.csv existe on n'exécute pas le knn imputer car c'est long\n",
    "if os.path.exists('data/df_complete_entire.csv'):\n",
    "    # File exists, perform actions accordingly\n",
    "    print(\"File exists! Not running knn\")\n",
    "    df_complete = pd.read_csv('data/df_complete_entire.csv')\n",
    "    df_complete = define_and_use_optimal_type(df_complete)\n",
    "    # Add your code here to handle the case when the file exists\n",
    "else:\n",
    "    # File does not exist, perform actions accordingly\n",
    "    print(\"File does not exist.\")\n",
    "    # Add your code here to handle the case when the file does not exist\n",
    "    # Créer un imputer KNN avec un nombre de voisins à considérer (k)\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    \n",
    "    # Imputer les valeurs manquantes pour les hommes\n",
    "    df_male[columns_to_impute] = imputer.fit_transform(df_male[columns_to_impute])\n",
    "    \n",
    "    # Imputer les valeurs manquantes pour les femmes\n",
    "    df_female[columns_to_impute] = imputer.fit_transform(df_female[columns_to_impute])\n",
    "    \n",
    "    # Fusionner les DataFrames pour obtenir le DataFrame complet\n",
    "    df_complete = pd.concat([df_male, df_female])\n",
    "    \n",
    "    df_complete = define_and_use_optimal_type(df_complete)\n",
    "    \n",
    "    df_complete.to_csv('data/df_complete_entire.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Aggrégation des médailles dans un dataframe, qui sera la base du dataframe d'entraînement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Création d'un nouveau dataframe aggrégeant toutes les données\n",
    "df_without_medals_duplicates = df_complete.drop_duplicates(subset=['Event', 'Country', 'Year', 'Medal'])\n",
    "participation_own_country_soviet = df_without_medals_duplicates[['Year','Country', 'Participation_own_country', 'Soviet_past']].drop_duplicates()\n",
    "\n",
    "df_without_medals_duplicates['Medal'] = df_without_medals_duplicates['Medal'].replace(np.nan, 0)\n",
    "df_without_medals_duplicates['Medal'] = df_without_medals_duplicates['Medal'].apply(lambda x: 0 if x==0 else 1)\n",
    "\n",
    "medals_per_year = df_without_medals_duplicates.groupby(['Country', 'Year']).agg({'Medal': 'sum'}).reset_index()\n",
    "df_agg_country_year_medals = medals_per_year.merge(participation_own_country_soviet, how='inner', on=['Country', 'Year'])\n",
    "\n",
    "# Optimisation\n",
    "df_agg_country_year_medals = define_and_use_optimal_type(df_agg_country_year_medals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_agg_country_year_medals = df_agg_country_year_medals[df_agg_country_year_medals['Year'] >= START_YEAR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On ajoute le nombre d'athlètes par année\n",
    "df_complete.drop_duplicates(subset=['Name', 'NOC', 'Year'], inplace=True)\n",
    "athlete_amount = (df_complete.groupby(['Country', 'Year']).size().to_frame())\n",
    "athlete_amount.reset_index(inplace=True)\n",
    "athlete_amount.rename(columns={0: 'AthletesNumber'}, inplace=True)\n",
    "\n",
    "df_agg_country_year_medals = df_agg_country_year_medals.merge(athlete_amount, how='inner', on=['Country', 'Year'])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pop_gdp_df.Year.max()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def impute_missing_values(df):\n",
    "    # Initialize KNN Imputer with default parameters\n",
    "    imputer = KNNImputer()\n",
    "\n",
    "    # Separate numerical and non-numerical columns\n",
    "    numerical_columns = df.select_dtypes(include=['number']).columns\n",
    "    non_numerical_columns = df.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "    # Impute missing values for numerical columns\n",
    "    if not numerical_columns.empty:\n",
    "        df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "    # For non-numerical columns, imputation is not possible with KNN Imputer\n",
    "    # You may choose to handle these columns separately based on your requirement\n",
    "\n",
    "    # Return the updated DataFrame\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On aggrège le GDP obtenu précédemment\n",
    "testest = df_agg_country_year_medals.merge(pop_gdp_df, on=['Country', 'Year'], how='left')\n",
    "\n",
    "testest = testest[testest.Year <= 2020]\n",
    "\n",
    "testest.to_csv('data/df_agg_country_year_medals_gdp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# On utilise le KNN ici pour pallier aux valeurs nulles\n",
    "testest = impute_missing_values(testest)\n",
    "\n",
    "# On met un type idéal\n",
    "testest = define_and_use_optimal_type(testest)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Récupération de la quantité d'athlètes de chaque sexe par pays\n",
    "# Create dummy variables for gender\n",
    "gender_dummies = pd.get_dummies(df_complete['Sex'], prefix='Gender')\n",
    "\n",
    "# Merge dummy variables into df_complete\n",
    "df_complete = pd.concat([df_complete, gender_dummies], axis=1)\n",
    "\n",
    "df_complete['Gender_F'].replace([False,True],[0, 1],inplace=True)\n",
    "df_complete['Gender_M'].replace([False,True],[0, 1],inplace=True)\n",
    "\n",
    "sexM_per_year = df_complete.groupby(['Country', 'Year']).agg({'Gender_M': 'sum'}).reset_index()\n",
    "sexF_per_year = df_complete.groupby(['Country', 'Year']).agg({'Gender_F': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nous avons un problème de qualité des données au niveau des femmes pour une raison inconnue (qui survient pendant le groupby). Ainsi pour obtenir le nombre exact de femmes à chaque fois, nous allons soustraire la quantité d'hommes à la quantité d'athlètes au total. \n",
    "\n",
    "df_gdp_soviet_athlete_sex = testest.merge(sexM_per_year, on=['Country', 'Year'], how='inner')\n",
    "df_gdp_soviet_athlete_sex['Gender_F'] = df_gdp_soviet_athlete_sex['AthletesNumber'] -df_gdp_soviet_athlete_sex['Gender_M']  \n",
    "\n",
    "# On créée des % et on drop les autres colonnes\n",
    "df_gdp_soviet_athlete_sex['Gender_F_Per'] = df_gdp_soviet_athlete_sex['Gender_F'] / df_gdp_soviet_athlete_sex['AthletesNumber'] \n",
    "df_gdp_soviet_athlete_sex['Gender_M_Per'] = df_gdp_soviet_athlete_sex['Gender_M'] / df_gdp_soviet_athlete_sex['AthletesNumber']\n",
    "\n",
    "df_gdp_soviet_athlete_sex.drop(columns=['Gender_F', 'Gender_M'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Test des modèles\n",
    "Ici, nous allons essayer plusieurs modèles de régression et nous allons comparer leur performance (sur la valeur Mean Square Error). Pour les tests, nous allons nous appuyer sur un échantillon de l'ensemble du dataframe, soit des années 1988 à 2020 ; et nous allons aussi essayer de prédire les valeurs de Tokyo dans un second temps en les excluant du jeu d'entraînement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Séparation du train et du test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On fait un train/test plus classique, avec toutes les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_gdp_soviet_athlete_sex[['Participation_own_country', 'Soviet_past', 'AthletesNumber', 'GDP_per_capita', 'Population', 'Urban Population(%)', 'Gender_F_Per', 'Gender_M_Per']], df_gdp_soviet_athlete_sex['Medal'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On garde un dataset de Tokyo pour tester à part\n",
    "df_train = df_gdp_soviet_athlete_sex[df_gdp_soviet_athlete_sex['Year'] != 2020]\n",
    "X_df_train = df_train[['Participation_own_country', 'Soviet_past', 'AthletesNumber',\n",
    "       'Population', 'GDP_per_capita', 'Urban Population(%)', 'Gender_F_Per',\n",
    "       'Gender_M_Per']]\n",
    "y_df_train = df_train['Medal']\n",
    "\n",
    "\n",
    "df_test = df_gdp_soviet_athlete_sex[df_gdp_soviet_athlete_sex['Year'] == 2020]\n",
    "X_df_test = df_test[['Participation_own_country', 'Soviet_past', 'AthletesNumber',\n",
    "       'Population', 'GDP_per_capita', 'Urban Population(%)', 'Gender_F_Per',\n",
    "       'Gender_M_Per']]\n",
    "y_df_test = df_test['Medal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Recherche des meilleurs paramètres des modèles\n",
    "Nous allons ici essayer plusieurs modèles, certains trouvés en cours et d'autres sur le web\n",
    "- LinearRegression\n",
    "- RandomForestRegressor\n",
    "- GradientBoostingRegressor\n",
    "- XGBoost\n",
    "\n",
    "Nous allons essayer dans un premier temps de trouver, pour chacun, les meilleurs hyperparamètres possibles, puis nous effectuerons notre choix sur la base de la MSE (Mean Square Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Essai de LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameters to search over\n",
    "param_grid = {\n",
    "    'fit_intercept': [True, False],\n",
    "    'positive': [True, False],\n",
    "    'copy_X': [True, False],\n",
    "    'n_jobs': [None, -1, 1, 2, 4],  # Adjust values as needed\n",
    "    # Add any other hyperparameters you want to tune\n",
    "}\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Create a grid search object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Perform grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters found by grid search\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Fit the model with the best parameters\n",
    "best_model = LinearRegression(**best_params)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Essai du RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_rf_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using the best model\n",
    "y_pred = best_rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Essai du GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [150],\n",
    "    'learning_rate': [0.05],\n",
    "    'max_depth': [3]\n",
    "}\n",
    "\n",
    "# Create a Gradient Boosting Regressor model\n",
    "gb_regressor = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the GridSearchCV object to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_gb_regressor = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test data using th    e best model\n",
    "y_pred = best_gb_regressor.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Test du XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the XGBRegressor model\n",
    "xgb_regressor = xgb.XGBRegressor(objective ='reg:squarederror')\n",
    "\n",
    "# Define the grid of parameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.1, 0.01, 0.001]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=xgb_regressor, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV object to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score (Negative Mean Squared Error):\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "En sachant que plus la Mean Square Error tend vers 0, meilleur le modèle est. \n",
    "Voici les résultats des modèles : \n",
    "- LinearRegression : MSE=28\n",
    "- RandomForestRegressor : MSE=10\n",
    "- GradientBoostingRegressor : MSE=11\n",
    "- XGBoost : MSE=-28\n",
    "\n",
    "Deux modèles sortent du lot : RandomForestRegressor et GradientBoostingRegressor. Nous allons ici utiliser le RandomForestRegressor avec les meilleurs paramètres trouvés par GridSearch, à savoir : {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
    "\n",
    "Il serait intéressant de connaitre l'importance des features liés à ce modèle.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importances = best_rf_regressor.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "On observe ici que la feature ayant le plus d'importance est celle reprenant le nombre d'athlètes, et de loin. Cela remet en perspective l'effort de récupération des autres données ..."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Récupération des données de 2024"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [500] used 6.6 MiB RAM in 0.61s (system mean cpu 39%, single max cpu 80%), peaked 0.0 MiB above final usage, current RAM usage now 70.2 MiB\n"
     ]
    }
   ],
   "source": [
    "tables = pd.read_html('https://en.wikipedia.org/wiki/2024_Summer_Olympics')\n",
    "athlete_per_country = tables[11]\n",
    "\n",
    "athlete_per_country.drop(columns=['Ranking'], inplace=True)\n",
    "athlete_per_country.rename({'NOC': 'Country', 'Athletes': 'AthletesNumber'}, axis=1, inplace=True)\n",
    "\n",
    "athlete_per_country['Year'] = 2024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.264598Z",
     "start_time": "2024-04-14T21:43:46.651063Z"
    }
   },
   "execution_count": 500
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                              Country  AthletesNumber  Year\n0                       United States             501  2024\n1                              France             485  2024\n2                           Australia             377  2024\n3                             Germany             309  2024\n4                               China             293  2024\n..                                ...             ...   ...\n153                            Monaco               1  2024\n154  Saint Vincent and the Grenadines               1  2024\n155                        San Marino               1  2024\n156                              Togo               1  2024\n157                      Turkmenistan               1  2024\n\n[158 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>AthletesNumber</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>501</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>France</td>\n      <td>485</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Australia</td>\n      <td>377</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Germany</td>\n      <td>309</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>China</td>\n      <td>293</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Monaco</td>\n      <td>1</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>154</th>\n      <td>Saint Vincent and the Grenadines</td>\n      <td>1</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>San Marino</td>\n      <td>1</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>156</th>\n      <td>Togo</td>\n      <td>1</td>\n      <td>2024</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>Turkmenistan</td>\n      <td>1</td>\n      <td>2024</td>\n    </tr>\n  </tbody>\n</table>\n<p>158 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [501] used 0.9 MiB RAM in 0.11s (system mean cpu 42%, single max cpu 88%), peaked 0.0 MiB above final usage, current RAM usage now 71.2 MiB\n"
     ]
    }
   ],
   "source": [
    "test_merge_2024 = countries_complete.merge(athlete_per_country, left_on=['Country_df_dict'], right_on=['Country'], how='right')\n",
    "test_merge_2024.drop(columns=['Country_df_iban'], inplace=True)\n",
    "athlete_per_country"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.377830Z",
     "start_time": "2024-04-14T21:43:47.266015Z"
    }
   },
   "execution_count": 501
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Country_df_dict                           Country  AthletesNumber  Year\n",
      "7               NaN                     Great Britain             267  2024\n",
      "18              NaN                       South Korea              97  2024\n",
      "44              NaN       Individual Neutral Athletes              37  2024\n",
      "48              NaN                    Chinese Taipei              30  2024\n",
      "61              NaN                         Angola[A]              20  2024\n",
      "86              NaN                       Ivory Coast               7  2024\n",
      "87              NaN                       North Korea               7  2024\n",
      "110             NaN              Refugee Olympic Team               3  2024\n",
      "116             NaN                        The Gambia               2  2024\n",
      "125             NaN                         Palestine               2  2024\n",
      "140             NaN  Democratic Republic of the Congo               1  2024\n",
      "147             NaN                            Kosovo               1  2024\n",
      "In [502] used 0.6 MiB RAM in 0.11s (system mean cpu 48%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 71.8 MiB\n"
     ]
    }
   ],
   "source": [
    "# On a quelques problèmes pour la correspondance, on créée une table de correspondance\n",
    "print(test_merge_2024[test_merge_2024['Country_df_dict'].isna()])\n",
    "\n",
    "# On supprime les données sur Individual Neutral Athletes, Chinese Taipei, Refugee Olympic Team, Kosovo, comme ils ne sont plus dans le dataframe d'origine suite à un nettoyage\n",
    "\n",
    "correspondance_2024 = {\n",
    "    'Great Britain': 'United Kingdom', \n",
    "    'South Korea': 'Korea, South',  \n",
    "    'Angola[A]' : 'Angola', \n",
    "    'Ivory Coast': \"Cote d'Ivoire\",\n",
    "    'North Korea': 'Korea, North', \n",
    "    'The Gambia': 'Gambia',\n",
    "    'Palestine': 'Palestine, Occupied Territories',\n",
    "    'Democratic Republic of the Congo': 'Congo, Dem Rep'\n",
    "}\n",
    "\n",
    "test_merge_2024['Country'] = test_merge_2024['Country'].replace(correspondance_2024)\n",
    "\n",
    "to_delete_2O24 = ['Individual Neutral Athletes', 'Chinese Taipei', 'Refugee Olympic Team', 'Kosovo']\n",
    "\n",
    "# Convert the list to a DataFrame\n",
    "to_delete_df = pd.DataFrame(to_delete_2O24, columns=['Country'])\n",
    "\n",
    "test_merge_2024.drop(columns=['Country_df_dict'], inplace=True)\n",
    "test_merge_2024 = test_merge_2024[~test_merge_2024['Country'].isin(to_delete_df['Country'])]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.489786Z",
     "start_time": "2024-04-14T21:43:47.379323Z"
    }
   },
   "execution_count": 502
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [503] used 0.1 MiB RAM in 0.10s (system mean cpu 45%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 71.9 MiB\n"
     ]
    }
   ],
   "source": [
    "#Participation_own_country\n",
    "test_merge_2024['Participation_own_country'] = np.where(test_merge_2024['Country'] == 'France', 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.599464Z",
     "start_time": "2024-04-14T21:43:47.493062Z"
    }
   },
   "execution_count": 503
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [504] used 0.5 MiB RAM in 0.11s (system mean cpu 40%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 72.4 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/1vcxjcxx0z75mdh8whh4pw6r0000gn/T/ipykernel_20885/287008703.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  soviet_past.drop(columns=['AthletesNumber', 'Population', 'GDP_per_capita', 'Urban Population(%)',\n"
     ]
    }
   ],
   "source": [
    "#Soviet_past = on reprend les mêmes valeurs que dans le dataframe de train\n",
    "soviet_past = df_gdp_soviet_athlete_sex.drop_duplicates(subset=['Country'])\n",
    "soviet_past.drop(columns=['AthletesNumber', 'Population', 'GDP_per_capita', 'Urban Population(%)',\n",
    "       'Gender_F_Per', 'Gender_M_Per', 'Medal', 'Participation_own_country', 'Year'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.710568Z",
     "start_time": "2024-04-14T21:43:47.600698Z"
    }
   },
   "execution_count": 504
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [505] used 0.1 MiB RAM in 0.11s (system mean cpu 28%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 72.5 MiB\n"
     ]
    }
   ],
   "source": [
    "test_merge_2024 = test_merge_2024.merge(soviet_past, on='Country', how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.822556Z",
     "start_time": "2024-04-14T21:43:47.711778Z"
    }
   },
   "execution_count": 505
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [506] used 0.0 MiB RAM in 0.11s (system mean cpu 26%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 72.6 MiB\n"
     ]
    }
   ],
   "source": [
    "# Les Jeux Olympiques de Paris 2024 étant déclarés comme étant les premiers jeux paritaire de l'histoire, nous partons du postulat que chaque pays envoie autant d'hommes que de femmes, ce qui résulte en une répartition parfaite de 50%/50%\n",
    "test_merge_2024['Gender_F_Per'] = test_merge_2024['Gender_M_Per'] = 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:47.931568Z",
     "start_time": "2024-04-14T21:43:47.823730Z"
    }
   },
   "execution_count": 506
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                              Country  AthletesNumber  Year  \\\n0                       United States             501  2024   \n1                              France             485  2024   \n2                           Australia             377  2024   \n3                             Germany             309  2024   \n4                               China             293  2024   \n..                                ...             ...   ...   \n149                            Monaco               1  2024   \n150  Saint Vincent and the Grenadines               1  2024   \n151                        San Marino               1  2024   \n152                              Togo               1  2024   \n153                      Turkmenistan               1  2024   \n\n     Participation_own_country  Soviet_past  Gender_F_Per  Gender_M_Per  \n0                            0            0           0.5           0.5  \n1                            1            0           0.5           0.5  \n2                            0            0           0.5           0.5  \n3                            0            0           0.5           0.5  \n4                            0            0           0.5           0.5  \n..                         ...          ...           ...           ...  \n149                          0            0           0.5           0.5  \n150                          0            0           0.5           0.5  \n151                          0            0           0.5           0.5  \n152                          0            0           0.5           0.5  \n153                          0            1           0.5           0.5  \n\n[154 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>AthletesNumber</th>\n      <th>Year</th>\n      <th>Participation_own_country</th>\n      <th>Soviet_past</th>\n      <th>Gender_F_Per</th>\n      <th>Gender_M_Per</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>501</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>France</td>\n      <td>485</td>\n      <td>2024</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Australia</td>\n      <td>377</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Germany</td>\n      <td>309</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>China</td>\n      <td>293</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>Monaco</td>\n      <td>1</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>Saint Vincent and the Grenadines</td>\n      <td>1</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>San Marino</td>\n      <td>1</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>Togo</td>\n      <td>1</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>153</th>\n      <td>Turkmenistan</td>\n      <td>1</td>\n      <td>2024</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.5</td>\n      <td>0.5</td>\n    </tr>\n  </tbody>\n</table>\n<p>154 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [507] used 0.1 MiB RAM in 0.11s (system mean cpu 22%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 72.6 MiB\n"
     ]
    }
   ],
   "source": [
    "test_merge_2024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:43:48.047220Z",
     "start_time": "2024-04-14T21:43:47.932832Z"
    }
   },
   "execution_count": 507
  },
  {
   "cell_type": "markdown",
   "source": [
    "N'ayant pas les données de la Banque Mondiale (même source que les données démographiques récupérées précédemment) sur les années 2023 et 2024, nous avons fait le choix de reprendre les données de 2022, afin de faciliter le traitement de ces dernières. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [519] used 4.6 MiB RAM in 0.12s (system mean cpu 47%, single max cpu 63%), peaked 0.0 MiB above final usage, current RAM usage now 82.9 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/38/1vcxjcxx0z75mdh8whh4pw6r0000gn/T/ipykernel_20885/909510630.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n"
     ]
    }
   ],
   "source": [
    "# On fait un KNN des valeurs démographiques manquantes comprises entre 2015 et 2023 pour avoir plus d'éléments, puis on filtre seulement les données de 2022\n",
    "pop_gdp_df_to_impute = pop_gdp_df[(pop_gdp_df['Year'] < 2023) & (pop_gdp_df['Year'] > 2015) ]\n",
    "pop_gdp_df_to_impute = impute_missing_values(pop_gdp_df_to_impute)\n",
    "pop_gdp_df_to_impute = pop_gdp_df_to_impute[pop_gdp_df_to_impute['Year'] == 2022]\n",
    "\n",
    "# Final training dataset\n",
    "final_df_test_2024 = test_merge_2024.merge(pop_gdp_df_to_impute, on='Country', how='inner')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:44:43.479688Z",
     "start_time": "2024-04-14T21:44:43.356133Z"
    }
   },
   "execution_count": 519
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [523] used -8.8 MiB RAM in 0.11s (system mean cpu 41%, single max cpu 65%), peaked 0.0 MiB above final usage, current RAM usage now 61.9 MiB\n"
     ]
    }
   ],
   "source": [
    "final_df_test_2024.drop(columns=['Year_x'], inplace=True)\n",
    "final_df_test_2024.rename({'Year_y': 'Year'}, axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:45:56.864835Z",
     "start_time": "2024-04-14T21:45:56.755563Z"
    }
   },
   "execution_count": 523
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "1984"
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [531] used -4.6 MiB RAM in 0.11s (system mean cpu 54%, single max cpu 75%), peaked 0.0 MiB above final usage, current RAM usage now 43.6 MiB\n"
     ]
    }
   ],
   "source": [
    "df_gdp_soviet_athlete_sex.Year.min()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:49:57.222363Z",
     "start_time": "2024-04-14T21:49:57.112499Z"
    }
   },
   "execution_count": 531
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Application du modèle\n",
    "Nous avons donc choisi d'utiliser le modèle RandomForestRegressor avec les paramètres suivants : \n",
    "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Country', 'Year', 'Medal', 'Participation_own_country', 'Soviet_past',\n       'AthletesNumber', 'Population', 'GDP_per_capita', 'Urban Population(%)',\n       'Gender_F_Per', 'Gender_M_Per'],\n      dtype='object')"
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [532] used 0.9 MiB RAM in 0.10s (system mean cpu 46%, single max cpu 63%), peaked 0.0 MiB above final usage, current RAM usage now 44.5 MiB\n"
     ]
    }
   ],
   "source": [
    "df_gdp_soviet_athlete_sex.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:50:19.926157Z",
     "start_time": "2024-04-14T21:50:19.819546Z"
    }
   },
   "execution_count": 532
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [542] used -24.5 MiB RAM in 0.36s (system mean cpu 39%, single max cpu 100%), peaked 0.0 MiB above final usage, current RAM usage now 50.7 MiB\n"
     ]
    }
   ],
   "source": [
    "# Train \n",
    "# df_gdp_soviet_athlete_sex\n",
    "X_train = df_gdp_soviet_athlete_sex[['Participation_own_country', 'Soviet_past',\n",
    "       'AthletesNumber', 'Population', 'GDP_per_capita', 'Urban Population(%)',\n",
    "       'Gender_F_Per', 'Gender_M_Per']]\n",
    "y_train = df_gdp_soviet_athlete_sex['Medal']\n",
    "\n",
    "\n",
    "# Test\n",
    "# final_df_test_2024\n",
    "X_test = final_df_test_2024\n",
    "\n",
    "hyperparameters = {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
    "\n",
    "# Create a Random Forest Regressor model\n",
    "rf_regressor = RandomForestRegressor(**hyperparameters, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_regressor.predict(X_test[['Participation_own_country', 'Soviet_past',\n",
    "       'AthletesNumber', 'Population', 'GDP_per_capita', 'Urban Population(%)',\n",
    "       'Gender_F_Per', 'Gender_M_Per']])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T21:58:59.142787Z",
     "start_time": "2024-04-14T21:58:58.778321Z"
    }
   },
   "execution_count": 542
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Country  Predictions\n",
      "0                       United States    99.000000\n",
      "1                              France    72.960000\n",
      "4                               China    53.747333\n",
      "3                             Germany    41.728000\n",
      "7                      United Kingdom    36.423333\n",
      "..                                ...          ...\n",
      "149  Saint Vincent and the Grenadines     0.007275\n",
      "124                          Suriname     0.007192\n",
      "104                           Bahamas     0.006972\n",
      "123                       Saint Lucia     0.005533\n",
      "103                             Aruba     0.005053\n",
      "\n",
      "[153 rows x 2 columns]\n",
      "In [554] used 1.2 MiB RAM in 0.11s (system mean cpu 32%, single max cpu 61%), peaked 0.0 MiB above final usage, current RAM usage now 47.4 MiB\n"
     ]
    }
   ],
   "source": [
    "# Extract country information from final_df_test_2024\n",
    "countries = final_df_test_2024['Country']\n",
    "\n",
    "# Create the olympic_2024_pred DataFrame with country and predictions\n",
    "olympic_2024_pred = pd.DataFrame({'Country': countries, 'Predictions': y_pred})\n",
    "\n",
    "# Display the olympic_2024_pred DataFrame\n",
    "print(olympic_2024_pred.sort_values(by='Predictions', ascending=False))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:08:10.032443Z",
     "start_time": "2024-04-14T22:08:09.923392Z"
    }
   },
   "execution_count": 554
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [555] used 0.1 MiB RAM in 0.11s (system mean cpu 60%, single max cpu 91%), peaked 0.0 MiB above final usage, current RAM usage now 47.5 MiB\n"
     ]
    }
   ],
   "source": [
    "sum_predicted_2024 = olympic_2024_pred['Predictions'].sum()\n",
    "expected_medals_2024 = 987\n",
    "\n",
    "evol_percentage =  expected_medals_2024 / sum_predicted_2024"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:08:11.236868Z",
     "start_time": "2024-04-14T22:08:11.127792Z"
    }
   },
   "execution_count": 555
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [558] used 0.0 MiB RAM in 0.11s (system mean cpu 43%, single max cpu 63%), peaked 0.0 MiB above final usage, current RAM usage now 47.6 MiB\n"
     ]
    }
   ],
   "source": [
    "# Ajustement en fonction du % d'évolution\n",
    "olympic_2024_pred['Predictions'] = round(olympic_2024_pred['Predictions']* evol_percentage)\n",
    "olympic_2024_pred['Predictions'] = olympic_2024_pred['Predictions'].astype('int')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:08:31.186702Z",
     "start_time": "2024-04-14T22:08:31.073367Z"
    }
   },
   "execution_count": 558
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                              Country  Predictions\n0                       United States          206\n1                              France          151\n2                           Australia           71\n3                             Germany           87\n4                               China          111\n..                                ...          ...\n148                            Monaco            0\n149  Saint Vincent and the Grenadines            0\n150                        San Marino            3\n151                              Togo            0\n152                      Turkmenistan            0\n\n[153 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Country</th>\n      <th>Predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>United States</td>\n      <td>206</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>France</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Australia</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Germany</td>\n      <td>87</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>China</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>Monaco</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>Saint Vincent and the Grenadines</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>San Marino</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>151</th>\n      <td>Togo</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>Turkmenistan</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>153 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In [559] used 0.4 MiB RAM in 0.11s (system mean cpu 45%, single max cpu 66%), peaked 0.0 MiB above final usage, current RAM usage now 48.1 MiB\n"
     ]
    }
   ],
   "source": [
    "olympic_2024_pred"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-14T22:08:32.196108Z",
     "start_time": "2024-04-14T22:08:32.082136Z"
    }
   },
   "execution_count": 559
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons prédit les médailles de 2024. Au total, lors de l'exécution de l'algorithme, nous avons conclu à un total de médailles distribué de 685. Or, dans la mesure où il y a 329 évènements prévus lors de Paris 2024, cela correspond à 987 médailles au total. \n",
    "Nous allons donc extrapoler le nombre de médailles en fonction, en effectuant une règle de 3. \n",
    "\n",
    "Cependant, il est important de noter que nous n'avons pas la totalité des compétiteurs dans cette liste, dans la mesure où nous avons retiré les réfugiés et les compétiteurs individuels (pour lesquels nous ne pouvons pas trouver de données) ; ainsi que quelques pays dont les données démographiques ne figuraient pas dans les données de la Banque Mondiale. \n",
    "\n",
    "Il semble aussi bon de rappeler que les données démographiques utilisées ici datent de 2022, alors qu'il aura fallu, dans l'idéal, les données de 2023, que nous n'avons malheureusement pas à notre disposition. "
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
